{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229683ed-750c-4a8d-8558-f2e175e3ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.extend(['Fyler', 'EvalFyler', 'Lib', 'Codes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf810ed-efd9-47ab-bec4-92907ebbc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb22cd-6f07-4f16-a9d6-9eb65b2a92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2f51c-31d3-4d80-b56b-d1b7f7e73383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Fyler import fyler_data, fyler_bow\n",
    "from EvalFyler import fyler_fextract, fyler_dataphenot\n",
    "from Lib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd097f30-26b8-4ea7-b8b2-abddc81c1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration\n",
    "example_cfg_path = 'example_cfgs/fyler_window_size-14_note_window_size-14_fyler_min_count-10_align-left.cfg'\n",
    "with open(example_cfg_path, 'r', encoding='utf8') as cfg_fd:\n",
    "    print(cfg_fd.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee430d5-bdc7-44b0-bcf1-42cc5b9ce669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "keep_defaults = False\n",
    "def set_vars(key, value):\n",
    "    if keep_defaults:\n",
    "        return os.environ.setdefault(key, value)\n",
    "    else:\n",
    "        os.environ[key] = value\n",
    "        return os.environ[key]\n",
    "\n",
    "############################################################\n",
    "# EDIT THIS STRING to point to your local ACHD mount path. #\n",
    "############################################################\n",
    "print(set_vars('ACHD', '/home/angus/mnt/ACHD'))\n",
    "\n",
    "print(set_vars('DATA_ROOT', os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0653f15-8a7e-4b85-9ece-3058807e205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "cfg = configparser.ConfigParser()\n",
    "cfg.read(example_cfg_path)\n",
    "root = os.path.expandvars(cfg.get(\"data\", \"root\"))\n",
    "\n",
    "notes_path = os.path.join(root, fyler_data.NOTE)\n",
    "text_path = os.path.join(root, fyler_data.TEXT)\n",
    "notes = fyler_data.open_notes(notes_path)\n",
    "\n",
    "cfg_name = os.path.splitext(os.path.basename(example_cfg_path))[0]\n",
    "tok_dir = pathlib.Path('models', cfg_name, 'tokenizer')\n",
    "tok_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f'{tok_dir=}')\n",
    "\n",
    "fdp = fyler_data.FylerDatasetProvider(\n",
    "    conn=notes,\n",
    "    note_dir=text_path,\n",
    "    input_vocab_size=cfg.get(\"args\", \"cui_vocab_size\"),\n",
    "    code_vocab_size=cfg.get(\"args\", \"code_vocab_size\"),\n",
    "    cfg=cfg['data'],\n",
    "    tokenizer_dir=tok_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1207d9-7337-45fe-9898-2afefa22d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "## copied from fyler_bow.main(Â·)\n",
    "## better to use fyler_bow.py directly in the command line but the process is reproduced here for clarity\n",
    "\n",
    "model_dir = pathlib.Path('models', cfg_name)\n",
    "device = None  # set this to the appropriate torch cuda device to use the GPU\n",
    "\n",
    "# Here we can see that instantiating a FylerDatasetProvider from an existing path loads the \n",
    "#  existing data instead of regenerating (unless data::regenerate is set to true in the config file)\n",
    "dp = fyler_data.FylerDatasetProvider(\n",
    "    conn=notes,\n",
    "    note_dir=text_path,\n",
    "    input_vocab_size=cfg.get(\"args\", \"cui_vocab_size\"),\n",
    "    code_vocab_size=cfg.get(\"args\", \"code_vocab_size\"),\n",
    "    cfg=cfg['data'],\n",
    "    tokenizer_dir=tok_dir,\n",
    ")\n",
    "\n",
    "in_seqs, out_seqs = dp.load_as_sequences()\n",
    "\n",
    "tr_in_seqs, val_in_seqs, tr_out_seqs, val_out_seqs = train_test_split(\n",
    "    in_seqs, out_seqs, test_size=0.10, random_state=2020\n",
    ")\n",
    "\n",
    "print(f\"loaded {len(tr_in_seqs)} training and {len(val_in_seqs)} validation samples\")\n",
    "\n",
    "max_cui_seq_len = max(len(seq) for seq in tr_in_seqs)\n",
    "print(\"longest cui sequence:\", max_cui_seq_len)\n",
    "\n",
    "max_code_seq_len = max(len(seq) for seq in tr_out_seqs)\n",
    "print(\"longest code sequence:\", max_code_seq_len)\n",
    "\n",
    "train_loader = fyler_bow.make_data_loader(\n",
    "    utils.sequences_to_matrix(tr_in_seqs, len(dp.input_tokenizer.stoi)),\n",
    "    utils.sequences_to_matrix(tr_out_seqs, len(dp.output_tokenizer.stoi)),\n",
    "    cfg.getint(\"model\", \"batch\"),\n",
    "    \"train\",\n",
    ")\n",
    "\n",
    "val_loader = fyler_bow.make_data_loader(\n",
    "    utils.sequences_to_matrix(val_in_seqs, len(dp.input_tokenizer.stoi)),\n",
    "    utils.sequences_to_matrix(val_out_seqs, len(dp.output_tokenizer.stoi)),\n",
    "    cfg.getint(\"model\", \"batch\"),\n",
    "    \"dev\",\n",
    ")\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model = fyler_bow.BagOfWords(\n",
    "    input_vocab_size=len(dp.input_tokenizer.stoi),\n",
    "    output_vocab_size=len(dp.output_tokenizer.stoi),\n",
    "    hidden_units=cfg.getint(\"model\", \"hidden\"),\n",
    "    dropout_rate=cfg.getfloat(\"model\", \"dropout\"),\n",
    "    model_dir=model_dir,\n",
    ")\n",
    "\n",
    "best_loss, optimal_epochs = fyler_bow.fit(\n",
    "    model, cfg, train_loader, val_loader, cfg.getint(\"model\", \"epochs\"),\n",
    "    model_dir=model_dir, device=device\n",
    ")\n",
    "print(\"best loss %.4f after %d epochs\" % (best_loss, optimal_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0247ea08-25d5-4e33-8498-66f04cd37c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get downstream config\n",
    "example_downstream_cfg_path = 'example_cfgs/experiment-cc-TGA_fyler_window_size-14_note_window_size-14_fyler_min_count-10_align-left.cfg'\n",
    "with open(example_downstream_cfg_path, 'r', encoding='utf8') as dcfg_fd:\n",
    "    print(dcfg_fd.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db3f35-9a90-4124-babb-392bade3cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downstream classifier training\n",
    "_ = fyler_fextract.train_model(\n",
    "    gpu=-1, \n",
    "    model_class=\"fyler\",\n",
    "    model_dir='models',\n",
    "    out_dir=None, \n",
    "    cfg_path=example_downstream_cfg_path,\n",
    ")\n",
    "\n",
    "# Clearly no learning is happening at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6712d5-eb78-4d8c-b47d-e7277ec33d24",
   "metadata": {},
   "source": [
    "#### What this looks like at the batch level:\n",
    "\n",
    "```sh\n",
    "$ # generate the different configurations for the encoders and the downstream tasks using base config files\n",
    "$ # gen_experiments.py currently has the phenotypes, window sizes, and minimum count parameter grid hard-coded\n",
    "$ python Fyler/gen_experiments.py pretrain \\\n",
    "    path/to/base_config.cfg \\\n",
    "    path/to/cfgs\n",
    "$ python Fyler/gen_experiments.py fextract \\\n",
    "    path/to/downstream/base_config.cfg \\\n",
    "    path/to/downstream/cfgs\n",
    "$ # generate the data into the directory specified in the config file\n",
    "$ python Fyler/experiments.py data \\\n",
    "    path/to/cfgs \\\n",
    "    --exclude path/to/excluded-cfgs.txt \\\n",
    "    -p num_cores \\\n",
    "    -o path/to/data/log/dir\n",
    "$ # train Fyler encoders\n",
    "$ python Fyler/fyler_bow.py batch \\\n",
    "    path/to/cfgs \\\n",
    "    path/to/data/dirs \\\n",
    "    path/to/fyler/encoders \\\n",
    "    --exclude path/to/excluded-downstream-cfgs.txt \\\n",
    "    -g num_gpus \\\n",
    "    -o path/to/fyler/log/dir\n",
    "$ # train downstream classifiers\n",
    "$ python EvalFyler/fyler_fextract.py batch \\\n",
    "    path/to/downstream/cfgs \\\n",
    "    path/to/fyler/encoders \\\n",
    "    --model_class fyler \\\n",
    "    --exclude path/to/excluded-downstream-cfgs.txt \\\n",
    "    -g num_gpus \\\n",
    "    -o path/to/downstream/log/dir\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7cf9c-0ae6-408b-beae-036c5ba4ef8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnlpt",
   "language": "python",
   "name": "cnlpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
